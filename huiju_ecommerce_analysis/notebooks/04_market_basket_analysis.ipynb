{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 惠聚电商平台用户品类偏好与消费行为深度分析\n",
    "\n",
    "## 阶段四：购物篮分析 (Market Basket Analysis)\n",
    "\n",
    "### 1. 引言与目标\n",
    "\n",
    "在前三个阶段，我们对用户画像、品类受欢迎程度、消费能力以及不同用户群体对品类的偏好进行了深入分析。现在，我们将进行购物篮分析，旨在发现不同商品品类之间共同购买的关联性。\n",
    "\n",
    "**本阶段目标**：\n",
    "1.  识别哪些商品品类经常被用户同时购买（频繁项集）。\n",
    "2.  挖掘品类之间的强关联规则 (e.g., \"购买了品类A的用户，有多大概率也会购买品类B?\")。\n",
    "3.  基于挖掘出的关联规则，为平台的交叉销售、捆绑销售、商品推荐、库存管理和营销活动提供数据驱动的建议。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mlxtend\n",
      "  Using cached mlxtend-0.23.4-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: scipy>=1.2.1 in /Users/liuqi/DAProject/.venv/lib/python3.12/site-packages (from mlxtend) (1.15.3)\n",
      "Requirement already satisfied: numpy>=1.16.2 in /Users/liuqi/DAProject/.venv/lib/python3.12/site-packages (from mlxtend) (2.2.6)\n",
      "Requirement already satisfied: pandas>=0.24.2 in /Users/liuqi/DAProject/.venv/lib/python3.12/site-packages (from mlxtend) (2.2.3)\n",
      "Requirement already satisfied: scikit-learn>=1.3.1 in /Users/liuqi/DAProject/.venv/lib/python3.12/site-packages (from mlxtend) (1.6.1)\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in /Users/liuqi/DAProject/.venv/lib/python3.12/site-packages (from mlxtend) (3.10.3)\n",
      "Requirement already satisfied: joblib>=0.13.2 in /Users/liuqi/DAProject/.venv/lib/python3.12/site-packages (from mlxtend) (1.5.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/liuqi/DAProject/.venv/lib/python3.12/site-packages (from matplotlib>=3.0.0->mlxtend) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/liuqi/DAProject/.venv/lib/python3.12/site-packages (from matplotlib>=3.0.0->mlxtend) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/liuqi/DAProject/.venv/lib/python3.12/site-packages (from matplotlib>=3.0.0->mlxtend) (4.58.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/liuqi/DAProject/.venv/lib/python3.12/site-packages (from matplotlib>=3.0.0->mlxtend) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/liuqi/DAProject/.venv/lib/python3.12/site-packages (from matplotlib>=3.0.0->mlxtend) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /Users/liuqi/DAProject/.venv/lib/python3.12/site-packages (from matplotlib>=3.0.0->mlxtend) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/liuqi/DAProject/.venv/lib/python3.12/site-packages (from matplotlib>=3.0.0->mlxtend) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/liuqi/DAProject/.venv/lib/python3.12/site-packages (from matplotlib>=3.0.0->mlxtend) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/liuqi/DAProject/.venv/lib/python3.12/site-packages (from pandas>=0.24.2->mlxtend) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/liuqi/DAProject/.venv/lib/python3.12/site-packages (from pandas>=0.24.2->mlxtend) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/liuqi/DAProject/.venv/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib>=3.0.0->mlxtend) (1.17.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/liuqi/DAProject/.venv/lib/python3.12/site-packages (from scikit-learn>=1.3.1->mlxtend) (3.6.0)\n",
      "Using cached mlxtend-0.23.4-py3-none-any.whl (1.4 MB)\n",
      "Installing collected packages: mlxtend\n",
      "Successfully installed mlxtend-0.23.4\n"
     ]
    }
   ],
   "source": [
    "!pip install mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始数据加载成功！\n",
      "用于购物篮分析的数据已准备，共 550068 条购买记录。\n",
      "   User_ID Product_Category\n",
      "0  1000001                3\n",
      "1  1000001                1\n",
      "2  1000001               12\n",
      "3  1000001               12\n",
      "4  1000002                8\n",
      "\n",
      "独立用户数: 5891\n",
      "独立商品品类数: 20\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 导入购物篮分析相关的库\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "from mlxtend.preprocessing import TransactionEncoder # 用于将数据转换为适合的格式\n",
    "\n",
    "# --- 绘图美化与中文支持配置 (与Notebook 02/03一致) ---\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('pastel')\n",
    "plt.rcParams['font.sans-serif'] = ['Arial Unicode MS'] # 替换为你系统中可用的中文字体\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.rcParams['axes.titlesize'] = 16\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 11\n",
    "plt.rcParams['ytick.labelsize'] = 11\n",
    "plt.rcParams['legend.fontsize'] = 10\n",
    "plt.rcParams['figure.titlesize'] = 18\n",
    "# --- 结束配置 ---\n",
    "\n",
    "# 配置pandas显示选项\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x) # 关联规则的指标可能小数位较多\n",
    "\n",
    "# 加载数据 (与Notebook 02/03一致，重新加载并进行类型转换)\n",
    "data_path = '../data/huiju_sales_data_2022_processed.csv'\n",
    "try:\n",
    "    df = pd.read_csv(data_path)\n",
    "    print(\"原始数据加载成功！\")\n",
    "    \n",
    "    # 保留需要的列，并确保 Product_Category 是字符串类型，方便后续处理\n",
    "    # 我们只需要 User_ID 和 Product_Category 来构建事务\n",
    "    df_mba = df[['User_ID', 'Product_Category']].copy()\n",
    "    df_mba['Product_Category'] = df_mba['Product_Category'].astype(str) # 转换为字符串，以作为离散项处理\n",
    "    \n",
    "    print(f\"用于购物篮分析的数据已准备，共 {len(df_mba)} 条购买记录。\")\n",
    "    print(df_mba.head())\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"错误：数据文件未在指定路径找到: {data_path}\")\n",
    "    df_mba = None\n",
    "except Exception as e:\n",
    "    print(f\"加载数据或初步处理时发生错误: {e}\")\n",
    "    df_mba = None\n",
    "\n",
    "if df_mba is not None:\n",
    "    print(f\"\\n独立用户数: {df_mba['User_ID'].nunique()}\")\n",
    "    print(f\"独立商品品类数: {df_mba['Product_Category'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 数据准备：构建事务数据\n",
    "\n",
    "购物篮分析算法（如Apriori）通常需要输入“事务”列表。一个事务代表一次购买行为中包含的商品集合。在我们的案例中，由于原始数据是每行一条购买记录（一个用户可能购买了多个品类，但分散在多行），我们需要将每个用户所有购买过的 **不同商品品类** 汇总起来，形成该用户的一个“事务”。\n",
    "\n",
    "例如，如果用户A购买了品类1、品类5、品类1，那么他/她的事务是 `{品类1, 品类5}`。\n",
    "\n",
    "我们将：\n",
    "1.  按 `User_ID` 分组。\n",
    "2.  对每个用户，获取其购买过的所有 `Product_Category` 的唯一值列表。\n",
    "3.  将这个列表数据转换为Apriori算法要求的one-hot编码格式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "按用户分组后的事务列表（部分）：\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_ID</th>\n",
       "      <th>Product_Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000001</td>\n",
       "      <td>[8, 16, 20, 4, 14, 12, 2, 5, 3, 6, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000002</td>\n",
       "      <td>[8, 20, 2, 5, 1, 6]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000003</td>\n",
       "      <td>[8, 18, 2, 5, 3, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000004</td>\n",
       "      <td>[1, 20]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000005</td>\n",
       "      <td>[8, 16, 4, 15, 3, 14, 11, 2, 5, 1, 6, 7]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User_ID                          Product_Category\n",
       "0  1000001     [8, 16, 20, 4, 14, 12, 2, 5, 3, 6, 1]\n",
       "1  1000002                       [8, 20, 2, 5, 1, 6]\n",
       "2  1000003                       [8, 18, 2, 5, 3, 1]\n",
       "3  1000004                                   [1, 20]\n",
       "4  1000005  [8, 16, 4, 15, 3, 14, 11, 2, 5, 1, 6, 7]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "One-hot 编码后的事务数据 (部分，显示每个用户是否购买了对应品类):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>2</th>\n",
       "      <th>20</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      1     10     11     12     13     14     15     16     17     18     19  \\\n",
       "0  True  False  False   True  False   True  False   True  False  False  False   \n",
       "1  True  False  False  False  False  False  False  False  False  False  False   \n",
       "2  True  False  False  False  False  False  False  False  False   True  False   \n",
       "3  True  False  False  False  False  False  False  False  False  False  False   \n",
       "4  True  False   True  False  False   True   True   True  False  False  False   \n",
       "\n",
       "       2     20      3      4      5      6      7      8      9  \n",
       "0   True   True   True   True   True   True  False   True  False  \n",
       "1   True   True  False  False   True   True  False   True  False  \n",
       "2   True  False   True  False   True  False  False   True  False  \n",
       "3  False   True  False  False  False  False  False  False  False  \n",
       "4   True  False   True   True   True   True   True   True  False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "One-hot 编码后的数据维度: (5891, 20)\n",
      "列名 (商品品类): ['1', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '2', '20', '3', '4', '5', '6', '7', '8', '9']\n"
     ]
    }
   ],
   "source": [
    "if df_mba is not None:\n",
    "    # 按User_ID分组，将每个用户购买的所有Product_Category汇总成列表\n",
    "    # 使用 set 去除同一用户购买同一品类的重复记录，确保每个品类在事务中只出现一次\n",
    "    transactions_grouped = df_mba.groupby('User_ID')['Product_Category'].apply(lambda x: list(set(x))).reset_index()\n",
    "    \n",
    "    # 查看转换后的部分数据\n",
    "    print(\"按用户分组后的事务列表（部分）：\")\n",
    "    display(transactions_grouped.head())\n",
    "    \n",
    "    # 将Product_Category列表提取出来，作为后续编码的输入\n",
    "    transactions_list = transactions_grouped['Product_Category'].tolist()\n",
    "    \n",
    "    # 使用TransactionEncoder将事务列表转换为适合Apriori算法的 one-hot 编码矩阵\n",
    "    # TransactionEncoder 会自动处理所有出现过的品类，并生成对应的列\n",
    "    te = TransactionEncoder()\n",
    "    te_ary = te.fit(transactions_list).transform(transactions_list)\n",
    "    \n",
    "    # 将one-hot编码后的数组转换回DataFrame，列名为商品品类ID\n",
    "    df_onehot = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "    \n",
    "    print(\"\\nOne-hot 编码后的事务数据 (部分，显示每个用户是否购买了对应品类):\")\n",
    "    display(df_onehot.head())\n",
    "    print(f\"\\nOne-hot 编码后的数据维度: {df_onehot.shape}\")\n",
    "    print(f\"列名 (商品品类): {df_onehot.columns.tolist()}\")\n",
    "\n",
    "else:\n",
    "    print(\"df_mba 未成功加载，无法进行后续处理。\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 应用Apriori算法挖掘频繁项集\n",
    "\n",
    "频繁项集是指那些经常一起出现的商品品类组合。Apriori算法通过迭代的方式找出这些组合。\n",
    "我们需要设定一个 **最小支持度 (min_support)** 阈值。支持度是指一个项集（品类组合）在所有事务中出现的比例。只有支持度大于等于该阈值的项集才被认为是频繁的。\n",
    "\n",
    "选择合适的 `min_support` 非常重要：\n",
    "*   太高：可能导致找不到足够的频繁项集。\n",
    "*   太低：可能产生大量意义不大的项集，并增加计算时间。\n",
    "\n",
    "我们将从一个相对较高的值开始尝试，然后根据结果进行调整。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始使用Apriori算法挖掘频繁项集，最小支持度设置为: 0.7\n",
      "Processing 4 combinations | Sampling itemset size 43\n",
      "\n",
      "挖掘出的频繁项集 (按支持度降序排列):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>support</th>\n",
       "      <th>itemsets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.97895</td>\n",
       "      <td>(1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.97623</td>\n",
       "      <td>(5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.96062</td>\n",
       "      <td>(8)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.95603</td>\n",
       "      <td>(1, 5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.94110</td>\n",
       "      <td>(8, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.94042</td>\n",
       "      <td>(8, 5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.92175</td>\n",
       "      <td>(8, 1, 5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.72925</td>\n",
       "      <td>(2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.72178</td>\n",
       "      <td>(2, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.71872</td>\n",
       "      <td>(2, 5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.71176</td>\n",
       "      <td>(2, 1, 5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.70922</td>\n",
       "      <td>(8, 2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.70243</td>\n",
       "      <td>(8, 1, 2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.70005</td>\n",
       "      <td>(8, 2, 5)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    support   itemsets\n",
       "0   0.97895        (1)\n",
       "2   0.97623        (5)\n",
       "3   0.96062        (8)\n",
       "5   0.95603     (1, 5)\n",
       "6   0.94110     (8, 1)\n",
       "9   0.94042     (8, 5)\n",
       "12  0.92175  (8, 1, 5)\n",
       "1   0.72925        (2)\n",
       "4   0.72178     (2, 1)\n",
       "7   0.71872     (2, 5)\n",
       "10  0.71176  (2, 1, 5)\n",
       "8   0.70922     (8, 2)\n",
       "11  0.70243  (8, 1, 2)\n",
       "13  0.70005  (8, 2, 5)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "共找到 14 个频繁项集。\n"
     ]
    }
   ],
   "source": [
    "if 'df_onehot' in locals() and df_onehot is not None and not df_onehot.empty:\n",
    "    # 设定最小支持度阈值\n",
    "    # 这个值需要根据数据和期望结果进行调整。\n",
    "    # 对于用户级别的事务数据，单个品类的支持度可能不会太高，组合品类的支持度会更低。\n",
    "    # 我们有约5891个独立用户事务。\n",
    "    # 如果一个项集出现59次，支持度约为 59/5891 = 0.01\n",
    "    # 先尝试一个相对保守的值，比如0.02 (意味着项集至少在约2%的用户事务中出现)\n",
    "    min_sup_threshold = 0.7\n",
    "    \n",
    "    print(f\"开始使用Apriori算法挖掘频繁项集，最小支持度设置为: {min_sup_threshold}\")\n",
    "    \n",
    "    frequent_itemsets = apriori(df_onehot, min_support=min_sup_threshold, use_colnames=True, verbose=1)\n",
    "    # use_colnames=True: 结果中的项集会使用列名（品类ID）而不是列的索引。\n",
    "    # verbose=1: 会打印出处理过程中的一些信息，如迭代次数和找到的项集数量。\n",
    "\n",
    "    if not frequent_itemsets.empty:\n",
    "        frequent_itemsets = frequent_itemsets.sort_values(by='support', ascending=False)\n",
    "        print(\"\\n挖掘出的频繁项集 (按支持度降序排列):\")\n",
    "        display(frequent_itemsets.head(20)) # 显示前20个\n",
    "        print(f\"\\n共找到 {len(frequent_itemsets)} 个频繁项集。\")\n",
    "\n",
    "        # 如果找到的频繁项集太少或太多，可以回头调整 min_sup_threshold\n",
    "        if len(frequent_itemsets) < 10:\n",
    "            print(\"警告：找到的频繁项集较少，可以尝试降低 min_support 阈值。\")\n",
    "        elif len(frequent_itemsets) > 1000: # 阈值可以根据实际情况调整\n",
    "            print(\"提示：找到的频繁项集较多，如果需要更精炼的结果，可以尝试提高 min_support 阈值。\")\n",
    "            \n",
    "    else:\n",
    "        print(f\"错误或未找到频繁项集。在最小支持度 {min_sup_threshold} 下没有项集满足条件。\")\n",
    "        print(\"建议尝试大幅降低 min_support 阈值，例如 0.005 或更低，然后逐步调整。\")\n",
    "\n",
    "else:\n",
    "    print(\"错误：One-hot编码数据 (df_onehot) 不存在或为空，无法进行Apriori分析。请检查Cell 4的执行结果。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "开始从频繁项集生成关联规则，最小置信度设置为: 0.9\n",
      "\n",
      "挖掘出的关联规则 (按提升度和置信度降序排列):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antecedents</th>\n",
       "      <th>consequents</th>\n",
       "      <th>support</th>\n",
       "      <th>confidence</th>\n",
       "      <th>lift</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>(2)</td>\n",
       "      <td>(8, 1)</td>\n",
       "      <td>0.70243</td>\n",
       "      <td>0.96322</td>\n",
       "      <td>1.02351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(2)</td>\n",
       "      <td>(1, 5)</td>\n",
       "      <td>0.71176</td>\n",
       "      <td>0.97602</td>\n",
       "      <td>1.02091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>(2)</td>\n",
       "      <td>(8, 5)</td>\n",
       "      <td>0.70005</td>\n",
       "      <td>0.95996</td>\n",
       "      <td>1.02078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>(2, 5)</td>\n",
       "      <td>(8)</td>\n",
       "      <td>0.70005</td>\n",
       "      <td>0.97402</td>\n",
       "      <td>1.01395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>(2, 1)</td>\n",
       "      <td>(8)</td>\n",
       "      <td>0.70243</td>\n",
       "      <td>0.97319</td>\n",
       "      <td>1.01309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(2)</td>\n",
       "      <td>(8)</td>\n",
       "      <td>0.70922</td>\n",
       "      <td>0.97253</td>\n",
       "      <td>1.01240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>(8, 2)</td>\n",
       "      <td>(1)</td>\n",
       "      <td>0.70243</td>\n",
       "      <td>0.99043</td>\n",
       "      <td>1.01172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(2, 5)</td>\n",
       "      <td>(1)</td>\n",
       "      <td>0.71176</td>\n",
       "      <td>0.99032</td>\n",
       "      <td>1.01161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>(8, 2)</td>\n",
       "      <td>(5)</td>\n",
       "      <td>0.70005</td>\n",
       "      <td>0.98708</td>\n",
       "      <td>1.01110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(2)</td>\n",
       "      <td>(1)</td>\n",
       "      <td>0.72178</td>\n",
       "      <td>0.98976</td>\n",
       "      <td>1.01104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(2, 1)</td>\n",
       "      <td>(5)</td>\n",
       "      <td>0.71176</td>\n",
       "      <td>0.98612</td>\n",
       "      <td>1.01013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(2)</td>\n",
       "      <td>(5)</td>\n",
       "      <td>0.71872</td>\n",
       "      <td>0.98557</td>\n",
       "      <td>1.00956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(1, 5)</td>\n",
       "      <td>(8)</td>\n",
       "      <td>0.92175</td>\n",
       "      <td>0.96413</td>\n",
       "      <td>1.00366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(8)</td>\n",
       "      <td>(1, 5)</td>\n",
       "      <td>0.92175</td>\n",
       "      <td>0.95953</td>\n",
       "      <td>1.00366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(8, 1)</td>\n",
       "      <td>(5)</td>\n",
       "      <td>0.92175</td>\n",
       "      <td>0.97944</td>\n",
       "      <td>1.00328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(5)</td>\n",
       "      <td>(8, 1)</td>\n",
       "      <td>0.92175</td>\n",
       "      <td>0.94418</td>\n",
       "      <td>1.00328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(8)</td>\n",
       "      <td>(5)</td>\n",
       "      <td>0.94042</td>\n",
       "      <td>0.97897</td>\n",
       "      <td>1.00280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(5)</td>\n",
       "      <td>(8)</td>\n",
       "      <td>0.94042</td>\n",
       "      <td>0.96331</td>\n",
       "      <td>1.00280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(8, 5)</td>\n",
       "      <td>(1)</td>\n",
       "      <td>0.92175</td>\n",
       "      <td>0.98014</td>\n",
       "      <td>1.00122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(1)</td>\n",
       "      <td>(8, 5)</td>\n",
       "      <td>0.92175</td>\n",
       "      <td>0.94156</td>\n",
       "      <td>1.00122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   antecedents consequents  support  confidence    lift\n",
       "20         (2)      (8, 1)  0.70243     0.96322 1.02351\n",
       "16         (2)      (1, 5)  0.71176     0.97602 1.02091\n",
       "23         (2)      (8, 5)  0.70005     0.95996 1.02078\n",
       "22      (2, 5)         (8)  0.70005     0.97402 1.01395\n",
       "19      (2, 1)         (8)  0.70243     0.97319 1.01309\n",
       "17         (2)         (8)  0.70922     0.97253 1.01240\n",
       "18      (8, 2)         (1)  0.70243     0.99043 1.01172\n",
       "15      (2, 5)         (1)  0.71176     0.99032 1.01161\n",
       "21      (8, 2)         (5)  0.70005     0.98708 1.01110\n",
       "12         (2)         (1)  0.72178     0.98976 1.01104\n",
       "14      (2, 1)         (5)  0.71176     0.98612 1.01013\n",
       "13         (2)         (5)  0.71872     0.98557 1.00956\n",
       "8       (1, 5)         (8)  0.92175     0.96413 1.00366\n",
       "9          (8)      (1, 5)  0.92175     0.95953 1.00366\n",
       "6       (8, 1)         (5)  0.92175     0.97944 1.00328\n",
       "11         (5)      (8, 1)  0.92175     0.94418 1.00328\n",
       "4          (8)         (5)  0.94042     0.97897 1.00280\n",
       "5          (5)         (8)  0.94042     0.96331 1.00280\n",
       "7       (8, 5)         (1)  0.92175     0.98014 1.00122\n",
       "10         (1)      (8, 5)  0.92175     0.94156 1.00122"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "共找到 24 条满足条件的关联规则。\n"
     ]
    }
   ],
   "source": [
    "if 'frequent_itemsets' in locals() and frequent_itemsets is not None and not frequent_itemsets.empty:\n",
    "    # 生成关联规则\n",
    "    # 我们可以使用不同的指标来评估规则，最常用的是 'confidence' 和 'lift'\n",
    "    # 我们先按 'confidence' (置信度) 来筛选，设置一个最小置信度阈值\n",
    "    min_confidence_threshold = 0.9  # 例如，规则的置信度至少为90%\n",
    "    \n",
    "    print(f\"\\n开始从频繁项集生成关联规则，最小置信度设置为: {min_confidence_threshold}\")\n",
    "    \n",
    "    rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=min_confidence_threshold)\n",
    "    \n",
    "    if not rules.empty:\n",
    "        # 对规则按 'lift' (提升度) 和 'confidence' (置信度) 降序排列，以便查看更有趣的规则\n",
    "        rules = rules.sort_values(['lift', 'confidence'], ascending=[False, False])\n",
    "        \n",
    "        print(\"\\n挖掘出的关联规则 (按提升度和置信度降序排列):\")\n",
    "        # 选择展示一些关键列，方便阅读\n",
    "        # 'antecedents' -> 前项 (如果买了这些)\n",
    "        # 'consequents' -> 后项 (那么可能买这些)\n",
    "        # 'support' -> 规则的支持度 (前项和后项一起出现的概率)\n",
    "        # 'confidence' -> 规则的置信度 (买了前项，有多大概率买后项)\n",
    "        # 'lift' -> 规则的提升度 (前项的出现对后项出现的概率提升了多少)\n",
    "        # 'leverage', 'conviction' 是其他衡量指标\n",
    "        display(rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']].head(20)) # 显示前20条规则\n",
    "        \n",
    "        print(f\"\\n共找到 {len(rules)} 条满足条件的关联规则。\")\n",
    "\n",
    "        if len(rules) < 5 and min_confidence_threshold > 0.1: # 如果规则太少，可以提示降低置信度\n",
    "             print(\"提示：找到的关联规则较少，可以尝试降低 min_confidence_threshold (例如 0.5 或 0.7)。\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"错误或未找到关联规则。在最小置信度 {min_confidence_threshold} 下没有规则满足条件。\")\n",
    "        print(f\"频繁项集数量: {len(frequent_itemsets)}\")\n",
    "        print(\"建议：\")\n",
    "        print(\"1. 检查频繁项集是否主要为单项集。如果是，可能需要降低Apriori的 min_support 以获得更多组合项集。\")\n",
    "        print(\"2. 大幅降低 association_rules 的 min_threshold (例如设置为0.1或更低)，然后逐步调整。\")\n",
    "\n",
    "else:\n",
    "    print(\"错误：频繁项集 (frequent_itemsets) 不存在或为空，无法生成关联规则。请检查Cell 6的执行结果和 min_support 设置。\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 关联规则解读与商业应用\n",
    "\n",
    "在设定最小支持度为0.7和最小置信度为0.9的条件下，我们成功挖掘出了24条强关联规则。这些规则主要揭示了平台核心品类之间的紧密购买联系。\n",
    "\n",
    "**关键指标回顾：**\n",
    "*   **Antecedents (前项)**: 规则的左手边，代表条件项集。\n",
    "*   **Consequents (后项)**: 规则的右手边，代表结果项集。\n",
    "*   **Support (规则支持度)**: 前项和后项一起在所有事务中出现的比例。由于我们的频繁项集筛选基于高支持度 (0.7)，所有规则的支持度都很高。\n",
    "*   **Confidence (置信度)**: 购买了前项的用户中，有多大比例也购买了后项。我们筛选的规则置信度均在0.9以上，表明关联性非常强。\n",
    "*   **Lift (提升度)**: Lift(A->B) = Conf(A->B) / Support(B)。\n",
    "    *   Lift > 1: 前项的出现提升了后项的购买概率（正相关）。\n",
    "    *   Lift = 1: 无关联。\n",
    "    *   Lift < 1: 负相关。\n",
    "\n",
    "**规则解读与洞察：**\n",
    "\n",
    "1.  **核心“铁三角”品类 (1, 5, 8) 的强绑定效应**：\n",
    "    *   我们观察到大量涉及品类1、品类5和品类8两两组合或三者组合的规则，它们的置信度都极高（通常 > 0.94）。\n",
    "        *   例如：`{1, 5} -> {8}` (conf: ~0.964)\n",
    "        *   例如：`{8, 1} -> {5}` (conf: ~0.979)\n",
    "        *   例如：`{8, 5} -> {1}` (conf: ~0.980)\n",
    "    *   **解读**：这清晰地表明，绝大多数用户在购物时会将这三个核心品类一起纳入考虑和购买。它们是用户购物篮中最常见、最稳固的组合。\n",
    "    *   **提升度分析**：虽然置信度很高，但这些核心品类之间的规则提升度普遍在1.00到1.004之间。这说明由于品类1, 5, 8本身就极其热门（独立支持度均>0.96），所以购买其中一个或两个对购买另一个的“额外提升”作用并不算非常大——因为用户本来就很有可能购买它们。然而，这并不减弱它们作为组合的强度。\n",
    "\n",
    "2.  **品类2作为核心组合的强力补充/关联者**：\n",
    "    *   规则如 ` {2} -> {8, 1}` (conf: ~0.963, lift: ~1.024) 和 ` {2} -> {1, 5}` (conf: ~0.976, lift: ~1.021) 非常引人注目。\n",
    "    *   **解读**：购买了品类2的用户，有超过96%的极高概率会同时购买核心组合（如品类8和1，或品类1和5）。品类2的出现对这些核心组合的购买具有一定的提升作用（lift > 1.02），是目前看到的提升度最高的规则组之一。这表明品类2与核心品类1, 5, 8之间存在非常强的正相关关系，品类2可能是驱动用户购买更多核心品类的一个重要“引子”，或者是在购买核心品类场景下的一个高频搭配品。\n",
    "    *   其他规则如 ` {2, 1} -> {8}` (conf: ~0.973) 或 ` {2, 5} -> {1}` (conf: ~0.990) 也印证了这一点。\n",
    "\n",
    "3.  **普遍的高支持度与高置信度**：\n",
    "    *   由于我们筛选的是高支持度的频繁项集，所有衍生出的规则自然也具有较高的支持度。这意味着这些购买模式在用户中非常普遍。\n",
    "    *   高置信度（>0.9）则进一步确认了这些品类组合的“确定性”——买了A，就极大概率会买B。\n",
    "\n",
    "**商业应用建议：**\n",
    "\n",
    "1.  **强化核心品类 (1, 5, 8) 的组合营销与体验优化**：\n",
    "    *   **捆绑促销/套餐设计**：鉴于品类1, 5, 8的“铁三角”关系，可以设计包含这三类商品的优惠套餐，或者在用户将其中任意两个加入购物车时，智能推荐第三个并给予小额组合优惠，以提升整体客单价和用户满足感。\n",
    "    *   **一站式购物场景构建**：在线上，可以在这些核心品类的商品详情页或品类着陆页之间设置便捷的交叉引导链接。在线下，可以将这三类商品规划在相近或易于流动的购物区域。\n",
    "    *   **库存与供应链协同**：确保这三个核心品类库存充足，尤其是在促销活动期间，避免因其中一个缺货而影响整个组合的销售。\n",
    "\n",
    "2.  **利用品类2的强关联效应进行交叉销售与引流**：\n",
    "    *   **精准推荐**：当用户将品类2的商品加入购物车或浏览品类2时，应优先、显著地向其推荐品类1、5、8的商品。\n",
    "    *   **营销活动设计**：可以将品类2作为参与门槛，例如“购买品类2商品满XX元，即可以优惠价换购品类1/5/8的指定商品”，或者“购买品类1/5/8的商品，即可以X折购买品类2商品”。\n",
    "    *   **品类2价值提升**：分析品类2的具体商品构成，如果其本身价值不高，可以思考如何通过与核心高价值品类（如品类1）的强关联来提升其“被看见”和“被顺带购买”的机会。\n",
    "\n",
    "3.  **基于高置信度规则优化推荐系统**：\n",
    "    *   虽然提升度不总是非常高，但极高的置信度本身就是推荐系统的重要依据。例如，如果规则 `A -> B` 的置信度是98%，那么在用户购买A后，推荐B的成功率会非常高。可以将这些高置信度规则直接应用于“购买此商品的用户还购买了”、“猜你喜欢”等推荐模块。\n",
    "\n",
    "4.  **考虑“反向”规则的意义（虽然此处Lift不高，但思路可借鉴）**：\n",
    "    *   例如，我们有 `(8) -> (1, 5)`。这意味着购买了品类8的用户也极大概率会买品类1和5。这可以用于在用户结账前或查看购物车时，进行“查漏补缺”式的提醒：“您可能还需要XX品类（1或5）的商品哦！”\n",
    "\n",
    "5.  **进一步探索（如果需要更细致的规则）**：\n",
    "    *   如果业务上希望找到一些非核心品类之间的、或者提升度更高的、但可能支持度和置信度略低的“惊喜”关联，可以适当**调低`min_support`和`min_confidence`阈值**，并重点关注**提升度（Lift）较高**的规则。不过，这可能会产生大量规则，需要更仔细的筛选和业务判断。以我们目前的高支持度设定，找到的强规则更多是围绕核心品类展开的。\n",
    "\n",
    "**总结**：\n",
    "本次购物篮分析成功地验证并量化了平台核心品类1、5、8之间的极强购买绑定关系，并发现了品类2作为这些核心品类强力补充者的角色。这些发现为平台在组合营销、交叉销售、商品推荐和运营策略优化方面提供了直接且有价值的参考。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
